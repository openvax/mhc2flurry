{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:tensorflow:Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "DEBUG:matplotlib.font_manager:font search path [PosixPath('/hpc/users/odonnt02/.conda/envs/py36b/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf'), PosixPath('/hpc/users/odonnt02/.conda/envs/py36b/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/afm'), PosixPath('/hpc/users/odonnt02/.conda/envs/py36b/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/pdfcorefonts')]\n",
      "DEBUG:root:Configured MHC2FLURRY_DOWNLOADS_DIR: /hpc/users/odonnt02/.local/share/mhc2flurry/1/0.0.1\n",
      "DEBUG:root:Configured MHCFLURRY_DOWNLOADS_DIR: /hpc/users/odonnt02/.local/share/mhcflurry/4/2.1.0\n",
      "WARNING:tensorflow:From <ipython-input-1-9f64c8989a71>:54: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA runtime implicit initialization on GPU:0 failed. Status: all CUDA-capable devices are busy or unavailable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9f64c8989a71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmhcflurry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregression_target\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_ic50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_ic50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m \u001b[0;34m;\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GPU AVAILABLE\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_gpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"GPU NOT AVAILABLE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/py36b/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m               instructions)\n\u001b[0;32m--> 340\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_deprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py36b/lib/python3.6/site-packages/tensorflow/python/framework/test_util.py\u001b[0m in \u001b[0;36mis_gpu_available\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1585\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mlocal_device\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1586\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlocal_device\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"GPU\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m         \u001b[0mgpu_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_capability_from_device_desc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py36b/lib/python3.6/site-packages/tensorflow/python/client/device_lib.py\u001b[0m in \u001b[0;36mlist_local_devices\u001b[0;34m(session_config)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mserialized_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   return [\n\u001b[0;32m---> 43\u001b[0;31m       \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_pywrap_device_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m   ]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA runtime implicit initialization on GPU:0 failed. Status: all CUDA-capable devices are busy or unavailable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import seaborn\n",
    "import logging\n",
    "import time\n",
    "import collections\n",
    "import os\n",
    "from os import environ\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import sklearn\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "import sklearn.linear_model\n",
    "\n",
    "%matplotlib inline\n",
    "logging.basicConfig(level=\"DEBUG\")\n",
    "pandas.set_option('display.max_columns', 60)\n",
    "\n",
    "from copy import deepcopy\n",
    "import shutil\n",
    "import bz2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def ppv(y_true, predictions):\n",
    "    df = pandas.DataFrame({\"prediction\": predictions, \"y_true\": y_true})\n",
    "    return df.sort_values(\"prediction\", ascending=False)[:int(y_true.sum())].y_true.mean()\n",
    "\n",
    "import logomaker\n",
    "\n",
    "import traceback\n",
    "import json\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from notebook.services.config import ConfigManager\n",
    "c = ConfigManager()\n",
    "c.update('notebook', {\"CodeCell\": {\"cm_config\": {\"autoCloseBrackets\": False}}})\n",
    "\n",
    "import mhcgnomes\n",
    "\n",
    "import mhc2flurry\n",
    "from mhc2flurry.downloads import get_path\n",
    "import mhc2flurry.allele_encoding_pair\n",
    "import mhc2flurry.allele_encoding\n",
    "import mhc2flurry.fasta\n",
    "import mhc2flurry.common\n",
    "import mhc2flurry.encodable_sequences\n",
    "\n",
    "from mhcflurry.regression_target import from_ic50, to_ic50\n",
    "\n",
    "import tensorflow as tf ; print(\"GPU AVAILABLE\" if tf.test.is_gpu_available() else \"GPU NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls \"$(mhc2flurry-downloads path data_curated)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"$(mhc2flurry-downloads path data_curated)/DOWNLOAD_INFO.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mhc2flurry-downloads info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_column_converters = {}\n",
    "for col in [\"proteins_human\", \"proteins_mouse\", \"proteins_viral\"]:\n",
    "    protein_column_converters[col] = str.split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_df = pandas.read_csv(\n",
    "    get_path(\"data_curated\", \"curated_training_data.csv.bz2\"),\n",
    "    converters=protein_column_converters)\n",
    "curated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_df.measurement_type.value_counts()\n",
    "curated_df.measurement_source.value_counts()\n",
    "curated_df.measurement_kind.value_counts()\n",
    "curated_df.loc[curated_df.measurement_kind == \"mass_spec\"].measurement_source.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_df.loc[curated_df.measurement_source.str.startswith(\"MS:pmid\")].measurement_source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_df.loc[curated_df.measurement_kind == \"mass_spec\"].measurement_inequality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_df = pandas.read_csv(\n",
    "    get_path(\"data_curated\", \"ms.by_pmid.csv.bz2\"),\n",
    "    converters=protein_column_converters)\n",
    "ms_df = ms_df.loc[\n",
    "    ms_df.mhc_class == \"II\"\n",
    "]\n",
    "ms_df[\"hla\"] = ms_df.hla.str.split().map(tuple)\n",
    "ms_df[\"allele_pairs\"] = ms_df.hla.map(mhc2flurry.common.make_allele_pairs).map(tuple)\n",
    "ms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: how to make pairs from e.g. HLA-DPA1*01:03, HLA-DPB1*04:01 ? Need to take all combinations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_df.original_pmid.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_df.proteins_human.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usable_ms_df = ms_df.loc[ms_df.proteins_human.str.len() > 0]\n",
    "len(usable_ms_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on monoallelic, validate on multiallelic\n",
    "train_df = usable_ms_df.loc[usable_ms_df.format == \"MONOALLELIC\"].copy()\n",
    "assert (train_df.allele_pairs.str.len() == 1).all()\n",
    "train_df[\"allele\"] = train_df.allele_pairs.str.get(0)\n",
    "train_df[\"parsed_allele\"] = train_df.allele.map(lambda s: mhcgnomes.parse(s, infer_class2_pairing=True))\n",
    "\n",
    "print(len(train_df))\n",
    "print(train_df.pmid.value_counts())\n",
    "train_df.allele.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = usable_ms_df.loc[~usable_ms_df.peptide.isin(train_df.peptide)]\n",
    "print(len(validation_df))\n",
    "print(validation_df.pmid.value_counts())\n",
    "validation_df.allele_pairs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins_df = mhc2flurry.fasta.read_fasta_to_dataframe(\n",
    "    get_path(\"data_proteomes\", \"human.uniprot.isoforms.fasta.gz\")).set_index(\"sequence_id\")\n",
    "proteins_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to match lengths of hits and decoys. I do not expect there is important information we want to learn in\n",
    "# the hit lengths.\n",
    "\n",
    "import random\n",
    "\n",
    "def add_decoys(hits_df, protein_to_sequence, protein_column=\"proteins_human\", decoys_per_hit=10):\n",
    "    \"\"\"\n",
    "    protein_to_sequence : dict like, str -> str\n",
    "        Map from protein names to full amino acid sequences\n",
    "        \n",
    "    protein_sequences_df : pandas.DataFrame\n",
    "        Should have columns: peptide, and the column specified in protein_column.\n",
    "        All other columns will be copied \n",
    "    \"\"\"\n",
    "    hits_df = hits_df.loc[hits_df[protein_column].str.len() > 0].copy()\n",
    "    hits_df[\"protein\"] = hits_df[protein_column].str.get(0) # For now just taking first. Later can use expression info.\n",
    "    hits_df[\"hit\"] = 1\n",
    "    hits_df[\"peptide_length\"] = hits_df.peptide.str.len()\n",
    "\n",
    "    # List of lists. Total number of lists is decoys_per_hit (e.g. 100).\n",
    "    # The i'th decoy peptide in each list is generated based on the \n",
    "    # i'th hit peptide.\n",
    "    decoy_peptides = [[] for _ in range(decoys_per_hit)]\n",
    "    \n",
    "    for protein, peptide_length in tqdm.tqdm(hits_df[[\"protein\", \"peptide_length\"]].itertuples(index=False), total=len(hits_df)):\n",
    "        sequence = protein_to_sequence[protein]\n",
    "        for decoy_set in decoy_peptides:\n",
    "            start = random.randrange(0, len(sequence) - peptide_length + 1)\n",
    "            decoy_set.append(sequence[start : start + peptide_length])\n",
    "        \n",
    "    decoy_dfs = []\n",
    "    for i in tqdm.tqdm(range(decoys_per_hit), total=decoys_per_hit):\n",
    "        df = hits_df.copy()\n",
    "        df[\"hit\"] = 0\n",
    "        df[\"peptide\"] = decoy_peptides.pop(0)\n",
    "        decoy_dfs.append(df)  \n",
    "        \n",
    "    result_df = pandas.concat([hits_df] + decoy_dfs, ignore_index=True)\n",
    "    return result_df\n",
    "\n",
    "\n",
    "validation_with_decoys_df = add_decoys(\n",
    "    validation_df,\n",
    "    proteins_df.sequence.to_dict(),\n",
    "    protein_column=\"proteins_human\",\n",
    "    decoys_per_hit=1)\n",
    "validation_with_decoys_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_decoys_df = add_decoys(\n",
    "    train_df,\n",
    "    proteins_df.sequence.to_dict(),\n",
    "    protein_column=\"proteins_human\",\n",
    "    decoys_per_hit=1)\n",
    "train_with_decoys_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (train_with_decoys_df.allele_pairs.str.len() == 1).all()\n",
    "train_with_decoys_df.allele.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_sequences_df = pandas.read_csv(get_path(\"allele_sequences\", \"allele_sequences.csv\"), index_col=0)\n",
    "allele_sequences_variant = allele_sequences_df.columns[0]\n",
    "print(\"using variant\", allele_sequences_variant)\n",
    "allele_sequences_alpha = allele_sequences_df.loc[allele_sequences_df.kind == \"alpha\", allele_sequences_variant]\n",
    "allele_sequences_beta = allele_sequences_df.loc[allele_sequences_df.kind == \"beta\", allele_sequences_variant]\n",
    "allele_sequences_alpha, allele_sequences_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mhc2flurry.amino_acid import COMMON_AMINO_ACIDS\n",
    "COMMON_AMINO_ACIDS\n",
    "\n",
    "aa_regex = \"^[%s]+$\" % \"\".join(sorted(COMMON_AMINO_ACIDS))\n",
    "aa_regex\n",
    "train_with_decoys_df.peptide.str.match(aa_regex).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_train_df = train_with_decoys_df.loc[\n",
    "    train_with_decoys_df.parsed_allele.map(\n",
    "        lambda p: isinstance(p, mhcgnomes.Class2Pair))\n",
    "].copy()\n",
    "print(\"Excluding\", train_with_decoys_df.loc[~train_with_decoys_df.index.isin(use_train_df.index)].allele.unique())\n",
    "\n",
    "use_train_df = use_train_df.loc[use_train_df.peptide.str.match(aa_regex)]\n",
    "\n",
    "use_train_df[\"alpha_allele\"] = train_with_decoys_df.parsed_allele.map(lambda p: p.alpha.to_string())\n",
    "use_train_df[\"beta_allele\"] = train_with_decoys_df.parsed_allele.map(lambda p: p.beta.to_string())\n",
    "\n",
    "use_train_df = use_train_df.loc[\n",
    "    (use_train_df.alpha_allele.isin(allele_sequences_alpha.index)) &\n",
    "    (use_train_df.beta_allele.isin(allele_sequences_beta.index))\n",
    "].copy()\n",
    "\n",
    "use_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df = use_train_df.loc[use_train_df.hit == 1].allele.value_counts().sort_index().to_frame()\n",
    "show_df.index.name = \"allele\"\n",
    "show_df.columns = ['peptides']\n",
    "show_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df.shape, show_df.peptides.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_with_decoys_df.pmid.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_multiallelic(df, hla_column=\"allele_pairs\"):\n",
    "    result = []\n",
    "    for allele_pairs, sub_df in tqdm.tqdm(df.groupby(\"allele_pairs\"), total=df[hla_column].nunique()):\n",
    "        sub_df = sub_df.copy()\n",
    "        sub_df[\"original_index\"] = sub_df.index\n",
    "            \n",
    "        for allele in allele_pairs:\n",
    "            sub_df = sub_df.copy()\n",
    "            parsed_allele = mhcgnomes.parse(allele, infer_class2_pairing=True)\n",
    "            #print(allele, parsed_allele)\n",
    "            sub_df[\"allele\"] = parsed_allele.to_string()\n",
    "            sub_df[\"parsed_allele\"] = parsed_allele\n",
    "            sub_df[\"alpha_allele\"] =  parsed_allele.alpha.to_string()\n",
    "            sub_df[\"beta_allele\"] =  parsed_allele.beta.to_string()\n",
    "            result.append(sub_df)\n",
    "    result = pandas.concat(result, ignore_index=True)\n",
    "    return result\n",
    "\n",
    "use_validation_df = flatten_multiallelic(validation_with_decoys_df)\n",
    "\n",
    "use_validation_df = use_validation_df.loc[\n",
    "    (use_validation_df.alpha_allele.isin(allele_sequences_alpha.index)) &\n",
    "    (use_validation_df.beta_allele.isin(allele_sequences_beta.index)) &\n",
    "    (use_validation_df.peptide.str.match(aa_regex))\n",
    "].copy()\n",
    "\n",
    "use_validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mhc2flurry.allele_encoding_pair\n",
    "import mhc2flurry.allele_encoding\n",
    "\n",
    "train_allele_encoding_pair = mhc2flurry.allele_encoding_pair.AlleleEncodingPair(\n",
    "    mhc2flurry.allele_encoding.AlleleEncoding(\n",
    "        use_train_df.alpha_allele.values,\n",
    "        allele_to_sequence=allele_sequences_alpha.to_dict()),\n",
    "    mhc2flurry.allele_encoding.AlleleEncoding(\n",
    "        use_train_df.beta_allele.values,\n",
    "        allele_to_sequence=allele_sequences_beta.to_dict()))\n",
    "train_allele_encoding_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_allele_encoding_pair = mhc2flurry.allele_encoding_pair.AlleleEncodingPair(\n",
    "    mhc2flurry.allele_encoding.AlleleEncoding(\n",
    "        use_validation_df.alpha_allele.values,\n",
    "        allele_to_sequence=allele_sequences_alpha.to_dict()),\n",
    "    mhc2flurry.allele_encoding.AlleleEncoding(\n",
    "        use_validation_df.beta_allele.values,\n",
    "        allele_to_sequence=allele_sequences_beta.to_dict()))\n",
    "validation_allele_encoding_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_peptides = mhc2flurry.encodable_sequences.EncodableSequences.create(use_train_df.peptide.values)\n",
    "validation_peptides = mhc2flurry.encodable_sequences.EncodableSequences.create(use_validation_df.peptide.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import mhc2flurry.condconv\n",
    "imp.reload(mhc2flurry.condconv)\n",
    "\n",
    "import mhc2flurry.class2_neural_network\n",
    "imp.reload(mhc2flurry.class2_neural_network)\n",
    "import mhc2flurry.class2_neural_network\n",
    "\n",
    "\n",
    "model = mhc2flurry.class2_neural_network.Class2NeuralNetwork(\n",
    "    minibatch_size=1024,\n",
    "    random_negative_rate=0.0,\n",
    "    random_negative_binder_threshold=2000,\n",
    "    layer_sizes=[],\n",
    "    patience=5,\n",
    "    dense_layer_l1_regularization=0.0,\n",
    "    peptide_convolutions=[\n",
    "        {'kernel_size': 9, 'filters': 64, 'activation': \"relu\"},\n",
    "        {'kernel_size': 1, 'filters': 16, 'activation': \"relu\"},\n",
    "        #{'kernel_size': 16, 'filters': 16, 'activation': \"relu\"},\n",
    "    ],\n",
    "    allele_dense_layer_sizes=[],\n",
    "    allele_positionwise_embedding_size=32,\n",
    "    activation=\"tanh\",\n",
    "    \n",
    "    \n",
    ")\n",
    "print(model.hyperparameters)\n",
    "\n",
    "#train_peptides = mhc2flurry.encodable_sequences.EncodableSequences.create(use_train_df.peptide.values)\n",
    "#validation_peptides = mhc2flurry.encodable_sequences.EncodableSequences.create(use_validation_df.peptide.values)\n",
    "fit_history = []\n",
    "epoch = 0\n",
    "def progress_callback(model=model):\n",
    "    global epoch\n",
    "    if epoch % 5 == 0:\n",
    "        start = time.time()\n",
    "        train_predictions = model.predict(\n",
    "            train_peptides,\n",
    "            allele_encoding_pair=train_allele_encoding_pair)\n",
    "        train_auc = sklearn.metrics.roc_auc_score(use_train_df.hit, train_predictions)\n",
    "        print(\"Train AUC [%0.3f sec]: %0.5f\" % (time.time() - start, train_auc))\n",
    "\n",
    "        start = time.time()\n",
    "        use_validation_df[\"prediction\"] = model.predict(\n",
    "            validation_peptides,\n",
    "            allele_encoding_pair=validation_allele_encoding_pair)\n",
    "        grouped = use_validation_df.groupby(\"original_index\")[[\"prediction\", \"hit\"]].max()\n",
    "        validation_auc = sklearn.metrics.roc_auc_score(grouped.hit.values, grouped.prediction.values)\n",
    "        print(\"Validation AUC [%0.3f sec]: %0.5f\" % (time.time() - start, validation_auc))\n",
    "        \n",
    "        validation_max_peptide_std = use_validation_df.groupby(\"peptide\").prediction.std().max()\n",
    "        print(\"Validation max peptide std\", validation_max_peptide_std)\n",
    "\n",
    "        fit_history.append((epoch, train_auc, validation_auc, validation_max_peptide_std))\n",
    "    epoch += 1\n",
    "\n",
    "model.fit(\n",
    "    use_train_df.peptide.values,\n",
    "    affinities=use_train_df.hit.values,\n",
    "    allele_encoding_pair=train_allele_encoding_pair,\n",
    "    progress_callback=progress_callback\n",
    ")\n",
    "\n",
    "fit_history = pandas.DataFrame(\n",
    "    fit_history, columns=[\"epoch\", \"train_auc\", \"validation_auc\", \"validation_max_peptide_std\"])\n",
    "fit_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.set_context('talk')\n",
    "pyplot.figure(figsize=(6,2))\n",
    "fit_history.set_index(\"epoch\")[[\"train_auc\", \"validation_auc\"]].rename(columns={\"train_auc\": \"Train\", \"validation_auc\": \"Validation\"}).plot(kind='line')\n",
    "seaborn.despine()\n",
    "pyplot.ylabel(\"Accuracy (AUC)\")\n",
    "pyplot.xlabel(\"Training Epoch\")\n",
    "pyplot.axhline(0.9013242464065097, label=\"Validation, NetMHCIIpan 4.0 EL\", ls=\"--\", color=\"green\")\n",
    "pyplot.legend()\n",
    "pyplot.ylim(ymin=0.5, ymax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.network().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_history.sort_values(\"validation_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_validation_df[\"prediction\"] = model.predict(\n",
    "    validation_peptides,\n",
    "    allele_encoding_pair=validation_allele_encoding_pair)\n",
    "grouped = use_validation_df.groupby(\"original_index\")[[\"prediction\", \"hit\"]].max()\n",
    "auc = sklearn.metrics.roc_auc_score(grouped.hit.values, grouped.prediction.values)\n",
    "print(\"Validation AUC: %0.5f\" % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_validation_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_df = use_validation_df[[\"pmid\", \"original_index\", \"sample_id\", \"peptide\", \"hit\", \"allele\", \"prediction\"]]\n",
    "write_df.to_csv(\"validation.csv\", index=False)\n",
    "!ls -lh validation.csv\n",
    "!bzip2 -f validation.csv\n",
    "!ls -lh validation.csv.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of motifs\n",
    "peptide_length = 9\n",
    "all_proteome_peptides = set()\n",
    "for seq in tqdm.tqdm(proteins_df.sequence.values):\n",
    "    for i in range(len(seq) - peptide_length):\n",
    "        all_proteome_peptides.add(seq[i : i + peptide_length])\n",
    "\n",
    "all_proteome_peptides = pandas.Series(sorted(all_proteome_peptides))\n",
    "all_proteome_peptides = all_proteome_peptides[all_proteome_peptides.str.match(aa_regex)]\n",
    "all_proteome_peptides = all_proteome_peptides.sample(frac=0.1)\n",
    "        \n",
    "proteome_predictions_df = pandas.DataFrame(index=all_proteome_peptides.values).sample(frac=0.1)\n",
    "proteome_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do predictions for motif visualization\n",
    "\n",
    "alleles_of_interest = list(train_df.allele.unique())\n",
    "alleles_of_interest\n",
    "\n",
    "proteome_peptides = mhc2flurry.encodable_sequences.EncodableSequences.create(proteome_predictions_df.index)\n",
    "for allele in tqdm.tqdm(alleles_of_interest):\n",
    "    parsed = mhcgnomes.parse(allele)\n",
    "    \n",
    "    proteome_predictions_df[allele] = model.predict(\n",
    "        proteome_peptides,\n",
    "        allele_encoding_pair=mhc2flurry.allele_encoding_pair.AlleleEncodingPair(\n",
    "            mhc2flurry.allele_encoding.AlleleEncoding(\n",
    "                [parsed.alpha.to_string()] * len(proteome_predictions_df),\n",
    "                allele_to_sequence=allele_sequences_alpha.to_dict()),\n",
    "            mhc2flurry.allele_encoding.AlleleEncoding(\n",
    "                [parsed.beta.to_string()] * len(proteome_predictions_df),\n",
    "                allele_to_sequence=allele_sequences_beta.to_dict())))\n",
    "proteome_predictions_df    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = proteome_predictions_df.sample(frac=0.01)\n",
    "plot_df.columns = plot_df.columns.str.replace(\"HLA-\", \"\").str.replace(\"DRA*01:01-\", \"\", regex=False).str.replace(\"-\", \"\\n\")\n",
    "\n",
    "seaborn.set_context('talk')\n",
    "pyplot.figure(figsize=(20,16))\n",
    "seaborn.pairplot(plot_df, kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time background_counts = logomaker.alignment_to_matrix(proteome_predictions_df.index.to_series().sample(frac=0.1))\n",
    "background_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_logo(allele):\n",
    "    top_peptides = proteome_predictions_df[allele].nlargest(int(len(proteome_predictions_df) * 0.01))\n",
    "    top_peptide_counts = logomaker.alignment_to_matrix(top_peptides.index.to_series())\n",
    "    pwm = logomaker.transform_matrix(\n",
    "        top_peptide_counts,\n",
    "        background=background_counts,\n",
    "        from_type='counts',\n",
    "        to_type='weight')\n",
    "    pwm.index += 1\n",
    "    adjusted_pwm = pwm.applymap(lambda value: value if value < 0 else value * 10)\n",
    "    \n",
    "    logomaker.Logo(adjusted_pwm)\n",
    "    pyplot.title(allele)\n",
    "    seaborn.despine()\n",
    "\n",
    "for allele in proteome_predictions_df.columns:\n",
    "    make_logo(allele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next step:\n",
    "# - Make a sequence logo of learned motifs\n",
    "# - Look at accuracy on individual alleles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "scores_df = []\n",
    "to_score = validation_df.copy()\n",
    "for allele, sub_validation_df in validation_df.groupby(\"hla\"):\n",
    "    to_score[\"hit\"] = 0\n",
    "    to_score.loc[sub_validation_df.index, \"hit\"] = 1\n",
    "    scores_df.append((\n",
    "        allele,\n",
    "        sklearn.metrics.roc_auc_score(to_score.hit, -1 * to_score.prediction),\n",
    "    ))\n",
    "\n",
    "scores_df = pandas.DataFrame(scores_df, columns=[\"allele\", \"auc\"])\n",
    "scores_df = scores_df.sort_values(\"auc\")\n",
    "\n",
    "seaborn.barplot(data=scores_df, y=\"allele\", x=\"auc\", color='black')\n",
    "#pyplot.xlim(xmin=0.5)\n",
    "pyplot.ylabel(\"Allele\")\n",
    "seaborn.despine()\n",
    "scores_df\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
